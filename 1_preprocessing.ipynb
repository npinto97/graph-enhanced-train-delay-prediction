{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing 10_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:03<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing 11_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:06<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing 12_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:02<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing 1_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:05<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing 2_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:02<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing 3_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:02<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing 4_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:06<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing 5_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:02<00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing 6_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:02<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing 7_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:07<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing 8_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:02<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing 9_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:02<00:00, 12.01it/s]\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = Path(\"data/raw/trains_dataset\")\n",
    "OUTPUT_PATH = Path(\"data/interim\")\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_all_data(base_path=BASE_PATH):\n",
    "    all_data = []\n",
    "    \n",
    "    # Scan monthly folders (1_2024, 2_2024, ...)\n",
    "    for month_folder in sorted(base_path.iterdir()):\n",
    "        if month_folder.is_dir():\n",
    "            print(f\" Processing {month_folder.name}...\")\n",
    "            \n",
    "            for file_path in tqdm(sorted(month_folder.glob(\"*.json\"))):\n",
    "                try:\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        data = json.load(f)\n",
    "                        \n",
    "                        if \"treni\" in data:\n",
    "                            all_data.extend(data[\"treni\"])\n",
    "                except (json.JSONDecodeError, FileNotFoundError) as e:\n",
    "                    print(f\" Errore nel file {file_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "df = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    \"_id\": \"train_id\",\n",
    "    \"n\": \"train_number\",\n",
    "    \"p\": \"departure_station\",\n",
    "    \"rp\": \"train_departure_delay\",\n",
    "    \"a\": \"arrival_station\",\n",
    "    \"ra\": \"train_arrival_platform\",\n",
    "    \"dl\": \"delay_info\",\n",
    "    \"c\": \"train_class\",\n",
    "    \"oo\": \"origin_station\",\n",
    "    \"od\": \"final_destination\",\n",
    "    \"op\": \"scheduled_departure_time\",\n",
    "    \"oa\": \"scheduled_arrival_time\",\n",
    "    \"pr\": \"train_status\",  # (Soppresso = Canceled)\n",
    "    \"sub\": \"train_subclass\",\n",
    "    \"sea\": \"extended_final_destination\",\n",
    "    \"cn\": \"connected_train\",\n",
    "    \"oae\": \"official_scheduled_arrival\",\n",
    "    \"oaz\": \"adjusted_scheduled_arrival\",\n",
    "    \"opz\": \"adjusted_scheduled_departure\",\n",
    "    \"ope\": \"official_planned_departure\",\n",
    "    \"sep\": \"starting_extended_point\",\n",
    "    \"fr\": \"route_stops\"\n",
    "}\n",
    "\n",
    "df.rename(columns=column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_to_datetime(series):\n",
    "    \"\"\"Convert timestamps to datetime safely, ensuring valid ranges.\"\"\"\n",
    "    MIN_TIMESTAMP = 1703980800  # Dec 31, 2023\n",
    "    MAX_TIMESTAMP = 1735756800  # Jan 1, 2025\n",
    "\n",
    "    # Se la serie Ã¨ giÃ  in datetime, la restituiamo cosÃ¬ com'Ã¨\n",
    "    if pd.api.types.is_datetime64_any_dtype(series):\n",
    "        return series  \n",
    "\n",
    "    series = pd.to_numeric(series, errors=\"coerce\")\n",
    "\n",
    "    series = series.where((series >= MIN_TIMESTAMP) & (series <= MAX_TIMESTAMP))\n",
    "\n",
    "    return pd.to_datetime(series, unit=\"s\", errors=\"coerce\")\n",
    "\n",
    "time_columns = [\"scheduled_departure_time\", \"scheduled_arrival_time\",\n",
    "                \"adjusted_scheduled_arrival\", \"adjusted_scheduled_departure\"]\n",
    "\n",
    "for col in time_columns:\n",
    "    df[col] = safe_to_datetime(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hhmmss_to_datetime(time_series, reference_series):\n",
    "    \"\"\"Convert HH:MM:SS format to full datetime using a reference date.\"\"\"\n",
    "    \n",
    "    reference_series = pd.to_datetime(reference_series, errors=\"coerce\")\n",
    "\n",
    "    time_series = pd.to_datetime(time_series, format=\"%H:%M:%S\", errors=\"coerce\").dt.time  \n",
    "\n",
    "    combined_str = reference_series.dt.strftime(\"%Y-%m-%d\") + \" \" + time_series.astype(str)\n",
    "\n",
    "    return pd.to_datetime(combined_str, format=\"%Y-%m-%d %H:%M:%S\", errors=\"coerce\")\n",
    "\n",
    "df[\"official_scheduled_arrival\"] = convert_hhmmss_to_datetime(df[\"official_scheduled_arrival\"], df[\"scheduled_arrival_time\"])\n",
    "df[\"official_planned_departure\"] = convert_hhmmss_to_datetime(df[\"official_planned_departure\"], df[\"scheduled_departure_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df.explode(\"route_stops\").reset_index(drop=True)\n",
    "\n",
    "# Remove any NaN values in \"route_stops\"\n",
    "df_exploded = df_exploded[df_exploded[\"route_stops\"].notna()]\n",
    "\n",
    "# Normalize the stops\n",
    "df_stops = pd.json_normalize(df_exploded[\"route_stops\"])\n",
    "\n",
    "stop_column_mapping = {\n",
    "    \"n\": \"stop_name\",\n",
    "    \"ra\": \"stop_arrival_delay\",\n",
    "    \"rp\": \"stop_departure_delay\",\n",
    "    \"br\": \"actual_platform\",\n",
    "    \"bp\": \"planned_platform\",\n",
    "    \"oa\": \"stop_arrival_time\",\n",
    "    \"op\": \"stop_departure_time\"\n",
    "}\n",
    "\n",
    "df_stops.rename(columns=stop_column_mapping, inplace=True)\n",
    "\n",
    "df_stops[\"train_id\"] = df_exploded[\"train_id\"].values\n",
    "df_stops[\"train_number\"] = df_exploded[\"train_number\"].values\n",
    "\n",
    "time_columns = [\"stop_arrival_time\", \"stop_departure_time\"]\n",
    "for col in time_columns:\n",
    "    df_stops[col] = safe_to_datetime(df_stops[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dati salvati con successo!\n"
     ]
    }
   ],
   "source": [
    "df.to_parquet(OUTPUT_PATH / \"train_data.parquet\", index=False)\n",
    "df_stops.to_parquet(OUTPUT_PATH / \"train_stops.parquet\", index=False)\n",
    "\n",
    "print(\"Dati salvati con successo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulizia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERIM_PATH = Path(\"data/interim\")\n",
    "PROCESSED_PATH = Path(\"data/processed\")\n",
    "PROCESSED_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_cleaned = pd.read_parquet(INTERIM_PATH / \"train_data.parquet\")\n",
    "df_stops = pd.read_parquet(INTERIM_PATH / \"train_stops.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_id                              0\n",
       "train_number                          0\n",
       "departure_station                     0\n",
       "train_departure_delay                 0\n",
       "arrival_station                       0\n",
       "train_arrival_platform                0\n",
       "train_status                    2820398\n",
       "train_class                           0\n",
       "scheduled_departure_time              0\n",
       "scheduled_arrival_time                0\n",
       "route_stops                         115\n",
       "delay_info                      2802422\n",
       "origin_station                  2802126\n",
       "final_destination               2802126\n",
       "connected_train                 2813986\n",
       "train_subclass                  2754555\n",
       "adjusted_scheduled_arrival      2844542\n",
       "extended_final_destination      2842527\n",
       "official_scheduled_arrival      2842534\n",
       "starting_extended_point         2842341\n",
       "official_planned_departure      2842341\n",
       "adjusted_scheduled_departure    2844861\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stop_name                      0\n",
       "stop_arrival_delay             0\n",
       "stop_departure_delay           0\n",
       "stop_arrival_time        2806447\n",
       "stop_departure_time      2829411\n",
       "actual_platform         32566314\n",
       "planned_platform        32614781\n",
       "train_id                       0\n",
       "train_number                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stops.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2845355, 22)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32995541, 9)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stops.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows before cleaning\n",
    "initial_rows_df = df_cleaned.shape[0]\n",
    "initial_rows_df_stops = df_stops.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rimuoviamo i treni soppressi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where train_status is \"Soppresso\"\n",
    "df_cleaned = df_cleaned[df_cleaned[\"train_status\"] != \"Soppresso\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_id                    0\n",
      "train_number                0\n",
      "departure_station           0\n",
      "train_departure_delay       0\n",
      "arrival_station             0\n",
      "train_arrival_platform      0\n",
      "train_class                 0\n",
      "scheduled_departure_time    0\n",
      "scheduled_arrival_time      0\n",
      "route_stops                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove columns with too many missing values or non-informative ones\n",
    "columns_to_drop = [\n",
    "    \"train_status\",\n",
    "    \"delay_info\",  # Testuale, non utile per la previsione\n",
    "    \"origin_station\", \"final_destination\",  # Pochi valori validi e ridondanti\n",
    "    \"connected_train\", \"train_subclass\", \"adjusted_scheduled_arrival\",\n",
    "    \"extended_final_destination\", \"official_scheduled_arrival\",\n",
    "    \"starting_extended_point\", \"official_planned_departure\", \"adjusted_scheduled_departure\"\n",
    "]\n",
    "df_cleaned.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of columns with >99% missing values\n",
    "columns_to_drop_stops = [\"actual_platform\", \"planned_platform\"]\n",
    "df_stops.drop(columns=columns_to_drop_stops, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il problema Ã¨ che alcune fermate previste sono state cancellate e quindi il treno non ha effettuato la sosta in quelle stazioni. Nell'esempio, vediamo che il treno 2855 doveva arrivare a Milano Rogoredo, ma Ã¨ stato cancellato su quella tratta e termina il viaggio a Milano Centrale.\n",
    "\n",
    "<div style=\"max-height: 300px; overflow-y: auto; border: 1px solid #ccc; padding: 10px;\" \n",
    "     onmouseover=\"this.style.overflowY='auto'\" \n",
    "     onmouseout=\"this.style.overflowY='hidden'\">\n",
    "\n",
    "```json\n",
    " {\n",
    "      \"_id\": \"2855-1704086040-Q09MSUNP\",\n",
    "      \"n\": \"2855\",\n",
    "      \"p\": \"COLICO\",\n",
    "      \"rp\": \"1\",\n",
    "      \"a\": \"MILANO CENTRALE\",\n",
    "      \"ra\": \"-3\",\n",
    "      \"dl\": \"Treno cancellato da SESTO S. GIOVANNI a MILANO ROGOREDO. Il treno oggi arriva a MILANO CENTRALE.\",\n",
    "      \"c\": \"REG\",\n",
    "      \"oo\": \"COLICO\",\n",
    "      \"od\": \"MILANO ROGOREDO\",\n",
    "      \"cn\": \"73467,MILANO GRECO PIRELLI\",\n",
    "      \"op\": 1704086040,\n",
    "      \"oa\": 1704093120,\n",
    "      \"fr\": [\n",
    "        {\n",
    "          \"n\": \"COLICO\",\n",
    "          \"ra\": \"N\",\n",
    "          \"rp\": \"1\",\n",
    "          \"oa\": 0,\n",
    "          \"op\": 1704086040\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"PIONA\",\n",
    "          \"ra\": \"-2\",\n",
    "          \"rp\": \"1\",\n",
    "          \"oa\": 1704086340,\n",
    "          \"op\": 1704086400\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"DORIO\",\n",
    "          \"ra\": \"0\",\n",
    "          \"rp\": \"-1\",\n",
    "          \"oa\": 1704086700,\n",
    "          \"op\": 1704086760\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"DERVIO\",\n",
    "          \"ra\": \"-3\",\n",
    "          \"rp\": \"0\",\n",
    "          \"oa\": 1704087060,\n",
    "          \"op\": 1704087120\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"BELLANO TARTAVELLE TERME\",\n",
    "          \"ra\": \"-1\",\n",
    "          \"rp\": \"5\",\n",
    "          \"oa\": 1704087480,\n",
    "          \"op\": 1704087540\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"VARENNA ESINO\",\n",
    "          \"ra\": \"4\",\n",
    "          \"rp\": \"5\",\n",
    "          \"oa\": 1704087780,\n",
    "          \"op\": 1704087840\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"FIUMELATTE\",\n",
    "          \"ra\": \"4\",\n",
    "          \"rp\": \"4\",\n",
    "          \"oa\": 1704087990,\n",
    "          \"op\": 1704088020\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"LIERNA\",\n",
    "          \"ra\": \"3\",\n",
    "          \"rp\": \"4\",\n",
    "          \"oa\": 1704088320,\n",
    "          \"op\": 1704088380\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"OLCIO\",\n",
    "          \"ra\": \"3\",\n",
    "          \"rp\": \"3\",\n",
    "          \"oa\": 1704088590,\n",
    "          \"op\": 1704088620\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"MANDELLO DEL LARIO\",\n",
    "          \"ra\": \"1\",\n",
    "          \"rp\": \"2\",\n",
    "          \"oa\": 1704088860,\n",
    "          \"op\": 1704088920\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"ABBADIA LARIANA\",\n",
    "          \"ra\": \"1\",\n",
    "          \"rp\": \"6\",\n",
    "          \"oa\": 1704089160,\n",
    "          \"op\": 1704089400\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"LECCO\",\n",
    "          \"ra\": \"5\",\n",
    "          \"rp\": \"4\",\n",
    "          \"oa\": 1704089820,\n",
    "          \"op\": 1704090000\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"CALOLZIOCORTE OLGINATE\",\n",
    "          \"ra\": \"2\",\n",
    "          \"rp\": \"3\",\n",
    "          \"oa\": 1704090420,\n",
    "          \"op\": 1704090480\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"CERNUSCO-MERATE\",\n",
    "          \"ra\": \"1\",\n",
    "          \"rp\": \"1\",\n",
    "          \"oa\": 1704091080,\n",
    "          \"op\": 1704091140\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"CARNATE USMATE\",\n",
    "          \"ra\": \"-3\",\n",
    "          \"rp\": \"-1\",\n",
    "          \"oa\": 1704091560,\n",
    "          \"op\": 1704091620\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"MONZA\",\n",
    "          \"ra\": \"-2\",\n",
    "          \"rp\": \"1\",\n",
    "          \"oa\": 1704092160,\n",
    "          \"op\": 1704092220\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"SESTO S. GIOVANNI\",\n",
    "          \"ra\": \"-1\",\n",
    "          \"rp\": \"1\",\n",
    "          \"oa\": 1704092520,\n",
    "          \"op\": 1704092580\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"MILANO LAMBRATE\",\n",
    "          \"ra\": \"S\",\n",
    "          \"rp\": \"S\",\n",
    "          \"oa\": 1704093240,\n",
    "          \"op\": 1704093300\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"MILANO FORLANINI\",\n",
    "          \"ra\": \"S\",\n",
    "          \"rp\": \"S\",\n",
    "          \"oa\": 1704093540,\n",
    "          \"op\": 1704093600\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"MILANO ROGOREDO\",\n",
    "          \"ra\": \"S\",\n",
    "          \"rp\": \"S\",\n",
    "          \"oa\": 1704093960,\n",
    "          \"op\": 0\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"MILANO CENTRALE\",\n",
    "          \"ra\": \"-3\",\n",
    "          \"rp\": \"N\",\n",
    "          \"oa\": 1704093120,\n",
    "          \"op\": 0\n",
    "        }\n",
    "      ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soluzione: cancelliamo le fermate saltate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fermate saltate rimosse. Il dataset finale contiene 32545672 fermate.\n"
     ]
    }
   ],
   "source": [
    "# Remove stops with \"S\" in arrival or departure delay\n",
    "df_stops = df_stops[~df_stops[\"stop_arrival_delay\"].astype(str).str.upper().eq(\"S\")]\n",
    "df_stops = df_stops[~df_stops[\"stop_departure_delay\"].astype(str).str.upper().eq(\"S\")]\n",
    "\n",
    "print(f\"Fermate saltate rimosse. Il dataset finale contiene {len(df_stops)} fermate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fermate che hanno ra = \"n.d.\" (ritardo all'arrivo non disponibile) o rp = \"n.d.\" (ritardo alla partenza non disponibile) rappresentano un caso particolare.\n",
    "Nel esempio, la fermata di Serravalle Scrivia ha ra = \"n.d.\", il che significa che non Ã¨ noto il ritardo all'arrivo per quella stazione.\n",
    "\n",
    "<div style=\"max-height: 300px; overflow-y: auto; border: 1px solid #ccc; padding: 10px;\">\n",
    "\n",
    "```json\n",
    "{\n",
    "      \"_id\": \"2116-1704086820-R0VOT1ZBIFAuUFJJTkNJUEU=\",\n",
    "      \"n\": \"2116\",\n",
    "      \"p\": \"GENOVA P.PRINCIPE\",\n",
    "      \"rp\": \"2\",\n",
    "      \"a\": \"TORINO P.NUOVA\",\n",
    "      \"ra\": \"-3\",\n",
    "      \"c\": \"REG\",\n",
    "      \"op\": 1704086820,\n",
    "      \"oa\": 1704094200,\n",
    "      \"fr\": [\n",
    "        {\n",
    "          \"n\": \"GENOVA P.PRINCIPE\",\n",
    "          \"ra\": \"N\",\n",
    "          \"rp\": \"2\",\n",
    "          \"oa\": 0,\n",
    "          \"op\": 1704086820\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"RONCO SCR.\",\n",
    "          \"ra\": \"0\",\n",
    "          \"rp\": \"2\",\n",
    "          \"oa\": 1704088200,\n",
    "          \"op\": 1704088260\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"ARQUATA SCRIVIA\",\n",
    "          \"ra\": \"1\",\n",
    "          \"rp\": \"4\",\n",
    "          \"oa\": 1704088740,\n",
    "          \"op\": 1704088800\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"SERRAVALLE SCRIVIA\",\n",
    "          \"ra\": \"n.d.\",\n",
    "          \"rp\": \"1\",\n",
    "          \"oa\": 1704089160,\n",
    "          \"op\": 1704089220\n",
    "        },\n",
    "        ...\n",
    "      ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soluzione: Sostituire \"n.d.\" con NaN (np.nan). \n",
    "Questo permette ai modelli di machine learning di gestire il valore come mancante senza distorcere i dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fermate con 'n.d.' gestite correttamente. Il dataset finale contiene 32545672 fermate.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert \"n.d.\" delays to NaN to handle them as missing values\n",
    "df_stops[\"stop_arrival_delay\"] = df_stops[\"stop_arrival_delay\"].replace(\"n.d.\", np.nan)\n",
    "df_stops[\"stop_departure_delay\"] = df_stops[\"stop_departure_delay\"].replace(\"n.d.\", np.nan)\n",
    "\n",
    "df_stops[\"stop_arrival_delay\"] = pd.to_numeric(df_stops[\"stop_arrival_delay\"], errors=\"coerce\")\n",
    "df_stops[\"stop_departure_delay\"] = pd.to_numeric(df_stops[\"stop_departure_delay\"], errors=\"coerce\")\n",
    "\n",
    "print(f\"Fermate con 'n.d.' gestite correttamente. Il dataset finale contiene {len(df_stops)} fermate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggirare il problema dell'orario di arrivo uguale a zero nella stazione di partenza e l'orario di partenza uguale a zero nelle stazioni di arriv:\n",
    "- Lasciare i valori mancanti come NaT (Not a Time): Nei dataframe di pandas, NaT Ã¨ lo standard per indicare un timestamp mancante, esattamente come NaN per i numeri. I modelli avanzati di machine learning possono gestire NaT senza problemi, mentre un valore errato come \"0\" potrebbe compromettere le previsioni.\n",
    "\n",
    "- Aggiungere una colonna is_terminal_stop: Questa colonna booleana (True/False) indica se la fermata Ã¨ la stazione iniziale o finale della tratta. In questo modo, possiamo identificare facilmente le fermate dove i valori di arrivo/partenza sono mancanti in modo legittimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_name                     0\n",
      "stop_arrival_delay            0\n",
      "stop_departure_delay          0\n",
      "stop_arrival_time       2765491\n",
      "stop_departure_time     2783550\n",
      "train_id                      0\n",
      "train_number                  0\n",
      "is_terminal_stop              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creation of the boolean column for terminal stops\n",
    "df_stops[\"is_terminal_stop\"] = df_stops[\"stop_arrival_time\"].isna() | df_stops[\"stop_departure_time\"].isna()\n",
    "\n",
    "# Fill with NaT instead of 0\n",
    "df_stops[\"stop_arrival_time\"] = pd.to_datetime(df_stops[\"stop_arrival_time\"], errors=\"coerce\")\n",
    "df_stops[\"stop_departure_time\"] = pd.to_datetime(df_stops[\"stop_departure_time\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_stops.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows after cleaning\n",
    "final_rows_df = df_cleaned.shape[0]\n",
    "final_rows_df_stops = df_stops.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati persi nel dataset dei treni: 24957 righe (0.88%)\n",
      "Dati persi nel dataset delle fermate: 449869 righe (1.36%)\n"
     ]
    }
   ],
   "source": [
    "loss_percentage_df = (1 - final_rows_df / initial_rows_df) * 100\n",
    "loss_percentage_stops = (1 - final_rows_df_stops / initial_rows_df_stops) * 100\n",
    "\n",
    "print(f\"Data lost in the train dataset: {initial_rows_df - final_rows_df} rows ({loss_percentage_df:.2f}%)\")\n",
    "print(f\"Data lost in the train stops dataset: {initial_rows_df_stops - final_rows_df_stops} righe ({loss_percentage_stops:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset puliti salvati con successo in 'data/interim'\n"
     ]
    }
   ],
   "source": [
    "INTERIM_PATH = Path(\"data/interim\")\n",
    "INTERIM_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_cleaned.to_parquet(INTERIM_PATH / \"train_data_cleaned.parquet\", index=False)\n",
    "df_stops.to_parquet(INTERIM_PATH / \"train_stops_cleaned.parquet\", index=False)\n",
    "\n",
    "print(\"Cleaned datasets successfully saved in 'data/interim'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
