{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train Data Preprocessing Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook processes train data collected from https://trainstats.altervista.org/.\n",
    "\n",
    "The goal is to load, clean, and structure the dataset to make it suitable for further analysis.\n",
    "\n",
    "The dataset contains information about train schedules, delays, and stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading JSON Data**\n",
    "\n",
    "We loop through each month and each daily JSON file, extracting:\n",
    "- General statistics (total monitored trains, delays, etc.).\n",
    "- Detailed train information (delays per train).\n",
    "- Alerts from RFI/TI about disruptions.\n",
    "\n",
    "Finally, all datasets are concatenated into full-year DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(\"data/raw/trains_dataset\")\n",
    "OUTPUT_PATH = Path(\"data/interim\")\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_all_data(base_path=BASE_PATH):\n",
    "    all_data = []\n",
    "    \n",
    "    # Scan monthly folders (1_2024, 2_2024, ...)\n",
    "    for month_folder in sorted(base_path.iterdir()):\n",
    "        if month_folder.is_dir():\n",
    "            print(f\" Processing {month_folder.name}...\")\n",
    "            \n",
    "            for file_path in tqdm(sorted(month_folder.glob(\"*.json\"))):\n",
    "                try:\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        data = json.load(f)\n",
    "                        \n",
    "                        if \"treni\" in data:\n",
    "                            all_data.extend(data[\"treni\"])\n",
    "                except (json.JSONDecodeError, FileNotFoundError) as e:\n",
    "                    print(f\" Errore nel file {file_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "    return pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 10_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 11_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 12_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 1_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 2_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 3_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 4_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 5_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 6_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 7_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 8_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:01<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 9_2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 13.72it/s]\n"
     ]
    }
   ],
   "source": [
    "df = load_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming Columns**\n",
    "\n",
    "The original column names are abbreviated. We'll map short codes to more descriptive column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    \"_id\": \"train_id\",\n",
    "    \"n\": \"train_number\",\n",
    "    \"p\": \"departure_station\",\n",
    "    \"rp\": \"train_departure_delay\",\n",
    "    \"a\": \"arrival_station\",\n",
    "    \"ra\": \"train_arrival_platform\",\n",
    "    \"dl\": \"delay_info\",\n",
    "    \"c\": \"train_class\",\n",
    "    \"oo\": \"origin_station\",\n",
    "    \"od\": \"final_destination\",\n",
    "    \"op\": \"scheduled_departure_time\",\n",
    "    \"oa\": \"scheduled_arrival_time\",\n",
    "    \"pr\": \"train_status\",  # (Soppresso = Canceled)\n",
    "    \"sub\": \"train_subclass\",\n",
    "    \"sea\": \"extended_final_destination\",\n",
    "    \"cn\": \"connected_train\",\n",
    "    \"oae\": \"official_scheduled_arrival\",\n",
    "    \"oaz\": \"adjusted_scheduled_arrival\",\n",
    "    \"opz\": \"adjusted_scheduled_departure\",\n",
    "    \"ope\": \"official_planned_departure\",\n",
    "    \"sep\": \"starting_extended_point\",\n",
    "    \"fr\": \"route_stops\"\n",
    "}\n",
    "\n",
    "df.rename(columns=column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting Time Columns**\n",
    "\n",
    "Convert UNIX timestamps into datetime format and ensure valid date ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_to_datetime(series):\n",
    "    \"\"\"Convert timestamps to datetime safely, ensuring valid ranges.\"\"\"\n",
    "    MIN_TIMESTAMP = 1703980800  # Dec 31, 2023\n",
    "    MAX_TIMESTAMP = 1735756800  # Jan 1, 2025\n",
    "\n",
    "    if pd.api.types.is_datetime64_any_dtype(series):\n",
    "        return series  \n",
    "\n",
    "    series = pd.to_numeric(series, errors=\"coerce\")\n",
    "\n",
    "    series = series.where((series >= MIN_TIMESTAMP) & (series <= MAX_TIMESTAMP))\n",
    "\n",
    "    return pd.to_datetime(series, unit=\"s\", errors=\"coerce\")\n",
    "\n",
    "time_columns = [\"scheduled_departure_time\", \"scheduled_arrival_time\",\n",
    "                \"adjusted_scheduled_arrival\", \"adjusted_scheduled_departure\"]\n",
    "\n",
    "for col in time_columns:\n",
    "    df[col] = safe_to_datetime(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling Train Stops**\n",
    "\n",
    "The \"route_stops\" column contains a list of dictionaries with stop details. We normalize them into a separate DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df.explode(\"route_stops\").reset_index(drop=True)\n",
    "\n",
    "# Remove any NaN values in \"route_stops\"\n",
    "df_exploded = df_exploded[df_exploded[\"route_stops\"].notna()]\n",
    "\n",
    "# Normalize the stops\n",
    "df_stops = pd.json_normalize(df_exploded[\"route_stops\"])\n",
    "\n",
    "stop_column_mapping = {\n",
    "    \"n\": \"stop_name\",\n",
    "    \"ra\": \"stop_arrival_delay\",\n",
    "    \"rp\": \"stop_departure_delay\",\n",
    "    \"br\": \"actual_platform\",\n",
    "    \"bp\": \"planned_platform\",\n",
    "    \"oa\": \"stop_arrival_time\",\n",
    "    \"op\": \"stop_departure_time\"\n",
    "}\n",
    "\n",
    "df_stops.rename(columns=stop_column_mapping, inplace=True)\n",
    "\n",
    "df_stops[\"train_id\"] = df_exploded[\"train_id\"].values\n",
    "df_stops[\"train_number\"] = df_exploded[\"train_number\"].values\n",
    "\n",
    "time_columns = [\"stop_arrival_time\", \"stop_departure_time\"]\n",
    "for col in time_columns:\n",
    "    df_stops[col] = safe_to_datetime(df_stops[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging Dataframes**\n",
    "\n",
    "Merge the train and stops datasets into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.merge(df_stops, on=\"train_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cleaning Missing Values and Removing Redundant Columns**\n",
    "\n",
    "We analyze missing values and remove non-informative or redundant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valori nulli nel dataset finale:\n",
      "                              Missing Values  Percentage\n",
      "train_status                        32728594       99.18\n",
      "route_stops                              115        0.00\n",
      "delay_info                          32355738       98.05\n",
      "origin_station                      32351228       98.04\n",
      "final_destination                   32351228       98.04\n",
      "connected_train                     32573766       98.71\n",
      "train_subclass                      32164517       97.47\n",
      "adjusted_scheduled_arrival          32989216       99.97\n",
      "extended_final_destination          32988668       99.97\n",
      "official_scheduled_arrival          32988780       99.97\n",
      "starting_extended_point             32987350       99.96\n",
      "official_planned_departure          32987350       99.96\n",
      "adjusted_scheduled_departure        32992976       99.98\n",
      "stop_name                                115        0.00\n",
      "stop_arrival_delay                       115        0.00\n",
      "stop_departure_delay                     115        0.00\n",
      "stop_arrival_time                    2806826        8.51\n",
      "stop_departure_time                  2829802        8.58\n",
      "actual_platform                     32570039       98.70\n",
      "planned_platform                    32618506       98.85\n",
      "train_number_y                           115        0.00\n"
     ]
    }
   ],
   "source": [
    "# Calculation and visualization of missing values\n",
    "missing_values = df_merged.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df_merged)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"Missing Values\": missing_values,\n",
    "    \"Percentage\": missing_percentage.round(2)\n",
    "})\n",
    "\n",
    "missing_summary = missing_summary[missing_summary[\"Missing Values\"] > 0]\n",
    "print(\"\\n Valori nulli nel dataset finale:\")\n",
    "print(missing_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows before cleaning\n",
    "initial_rows_df = df_merged.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We remove rows containing suppressed trains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where train_status is \"Soppresso\"\n",
    "df_merged = df_merged[df_merged[\"train_status\"] != \"Soppresso\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with too many missing values or non-informative ones\n",
    "columns_to_drop = [\n",
    "    \"train_status\",\n",
    "    \"delay_info\",  # Textual, not useful for prediction\n",
    "    \"origin_station\", \"final_destination\",  # Few valid and redundant values\n",
    "    \"connected_train\", \"train_subclass\", \"adjusted_scheduled_arrival\",\n",
    "    \"extended_final_destination\", \"official_scheduled_arrival\",\n",
    "    \"starting_extended_point\", \"official_planned_departure\", \"adjusted_scheduled_departure\",\n",
    "    \"actual_platform\", \"planned_platform\"  # Removal of columns with >99% missing values\n",
    "]\n",
    "df_merged.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Null values in the final dataset:\n",
      "                     Missing Values  Percentage\n",
      "stop_arrival_time           2781911        8.50\n",
      "stop_departure_time         2804887        8.57\n"
     ]
    }
   ],
   "source": [
    "# Calculation and visualization of missing values\n",
    "missing_values = df_merged.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df_merged)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"Missing Values\": missing_values,\n",
    "    \"Percentage\": missing_percentage.round(2)\n",
    "})\n",
    "\n",
    "missing_summary = missing_summary[missing_summary[\"Missing Values\"] > 0]\n",
    "print(\"\\n Null values in the final dataset:\")\n",
    "print(missing_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We remove deleted stops**\n",
    "\n",
    "The problem is that some scheduled stops have been cancelled, so the train did not make the stop at those stations. \n",
    "\n",
    "In the example, we see that train 2855 was supposed to arrive at Milano Rogoredo, but it was cancelled on that route and ends its journey at Milano Centrale. \n",
    "\n",
    "We solve by removing those lines.\n",
    "\n",
    "<div style=\"max-height: 300px; overflow-y: auto; border: 1px solid #ccc; padding: 10px;\" \n",
    "     onmouseover=\"this.style.overflowY='auto'\" \n",
    "     onmouseout=\"this.style.overflowY='hidden'\">\n",
    "\n",
    "```json\n",
    " {\n",
    "      \"_id\": \"2855-1704086040-Q09MSUNP\",\n",
    "      \"n\": \"2855\",\n",
    "      \"p\": \"COLICO\",\n",
    "      \"rp\": \"1\",\n",
    "      \"a\": \"MILANO CENTRALE\",\n",
    "      \"ra\": \"-3\",\n",
    "      \"dl\": \"Treno cancellato da SESTO S. GIOVANNI a MILANO ROGOREDO. Il treno oggi arriva a MILANO CENTRALE.\",\n",
    "      \"c\": \"REG\",\n",
    "      \"oo\": \"COLICO\",\n",
    "      \"od\": \"MILANO ROGOREDO\",\n",
    "      \"cn\": \"73467,MILANO GRECO PIRELLI\",\n",
    "      \"op\": 1704086040,\n",
    "      \"oa\": 1704093120,\n",
    "      \"fr\": [\n",
    "        {\n",
    "          \"n\": \"COLICO\",\n",
    "          \"ra\": \"N\",\n",
    "          \"rp\": \"1\",\n",
    "          \"oa\": 0,\n",
    "          \"op\": 1704086040\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"PIONA\",\n",
    "          \"ra\": \"-2\",\n",
    "          \"rp\": \"1\",\n",
    "          \"oa\": 1704086340,\n",
    "          \"op\": 1704086400\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"DORIO\",\n",
    "          \"ra\": \"0\",\n",
    "          \"rp\": \"-1\",\n",
    "          \"oa\": 1704086700,\n",
    "          \"op\": 1704086760\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"DERVIO\",\n",
    "          \"ra\": \"-3\",\n",
    "          \"rp\": \"0\",\n",
    "          \"oa\": 1704087060,\n",
    "          \"op\": 1704087120\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"BELLANO TARTAVELLE TERME\",\n",
    "          \"ra\": \"-1\",\n",
    "          \"rp\": \"5\",\n",
    "          \"oa\": 1704087480,\n",
    "          \"op\": 1704087540\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"VARENNA ESINO\",\n",
    "          \"ra\": \"4\",\n",
    "          \"rp\": \"5\",\n",
    "          \"oa\": 1704087780,\n",
    "          \"op\": 1704087840\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"FIUMELATTE\",\n",
    "          \"ra\": \"4\",\n",
    "          \"rp\": \"4\",\n",
    "          \"oa\": 1704087990,\n",
    "          \"op\": 1704088020\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"LIERNA\",\n",
    "          \"ra\": \"3\",\n",
    "          \"rp\": \"4\",\n",
    "          \"oa\": 1704088320,\n",
    "          \"op\": 1704088380\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"OLCIO\",\n",
    "          \"ra\": \"3\",\n",
    "          \"rp\": \"3\",\n",
    "          \"oa\": 1704088590,\n",
    "          \"op\": 1704088620\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"MANDELLO DEL LARIO\",\n",
    "          \"ra\": \"1\",\n",
    "          \"rp\": \"2\",\n",
    "          \"oa\": 1704088860,\n",
    "          \"op\": 1704088920\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"ABBADIA LARIANA\",\n",
    "          \"ra\": \"1\",\n",
    "          \"rp\": \"6\",\n",
    "          \"oa\": 1704089160,\n",
    "          \"op\": 1704089400\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"LECCO\",\n",
    "          \"ra\": \"5\",\n",
    "          \"rp\": \"4\",\n",
    "          \"oa\": 1704089820,\n",
    "          \"op\": 1704090000\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"CALOLZIOCORTE OLGINATE\",\n",
    "          \"ra\": \"2\",\n",
    "          \"rp\": \"3\",\n",
    "          \"oa\": 1704090420,\n",
    "          \"op\": 1704090480\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"CERNUSCO-MERATE\",\n",
    "          \"ra\": \"1\",\n",
    "          \"rp\": \"1\",\n",
    "          \"oa\": 1704091080,\n",
    "          \"op\": 1704091140\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"CARNATE USMATE\",\n",
    "          \"ra\": \"-3\",\n",
    "          \"rp\": \"-1\",\n",
    "          \"oa\": 1704091560,\n",
    "          \"op\": 1704091620\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"MONZA\",\n",
    "          \"ra\": \"-2\",\n",
    "          \"rp\": \"1\",\n",
    "          \"oa\": 1704092160,\n",
    "          \"op\": 1704092220\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"SESTO S. GIOVANNI\",\n",
    "          \"ra\": \"-1\",\n",
    "          \"rp\": \"1\",\n",
    "          \"oa\": 1704092520,\n",
    "          \"op\": 1704092580\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"MILANO LAMBRATE\",\n",
    "          \"ra\": \"S\",\n",
    "          \"rp\": \"S\",\n",
    "          \"oa\": 1704093240,\n",
    "          \"op\": 1704093300\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"MILANO FORLANINI\",\n",
    "          \"ra\": \"S\",\n",
    "          \"rp\": \"S\",\n",
    "          \"oa\": 1704093540,\n",
    "          \"op\": 1704093600\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"MILANO ROGOREDO\",\n",
    "          \"ra\": \"S\",\n",
    "          \"rp\": \"S\",\n",
    "          \"oa\": 1704093960,\n",
    "          \"op\": 0\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"MILANO CENTRALE\",\n",
    "          \"ra\": \"-3\",\n",
    "          \"rp\": \"N\",\n",
    "          \"oa\": 1704093120,\n",
    "          \"op\": 0\n",
    "        }\n",
    "      ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped stops removed. The final dataset contains 32549240 stops.\n"
     ]
    }
   ],
   "source": [
    "# Remove stops with \"S\" in arrival or departure delay\n",
    "df_merged = df_merged[~df_merged[\"stop_arrival_delay\"].astype(str).str.upper().eq(\"S\")]\n",
    "df_merged = df_merged[~df_merged[\"stop_departure_delay\"].astype(str).str.upper().eq(\"S\")]\n",
    "\n",
    "print(f\"Skipped stops removed. The final dataset contains {len(df_merged)} stops.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schedule not available with NaT**.\n",
    "\n",
    "Stops that have ra = “n.d.” (arrival delay not available) or rp = “n.d.” (departure delay unavailable) represent a special case.\n",
    "In the example, the Serravalle Scrivia stop has ra = “n.d.,” which means that the arrival delay for that station is not known.\n",
    "\n",
    "We solve replacacing “n.d.” with NaN (np.nan). \n",
    "This allows machine learning models to handle the value as missing without skewing the data.\n",
    "\n",
    "<div style=\"max-height: 300px; overflow-y: auto; border: 1px solid #ccc; padding: 10px;\">\n",
    "\n",
    "```json\n",
    "{\n",
    "      \"_id\": \"2116-1704086820-R0VOT1ZBIFAuUFJJTkNJUEU=\",\n",
    "      \"n\": \"2116\",\n",
    "      \"p\": \"GENOVA P.PRINCIPE\",\n",
    "      \"rp\": \"2\",\n",
    "      \"a\": \"TORINO P.NUOVA\",\n",
    "      \"ra\": \"-3\",\n",
    "      \"c\": \"REG\",\n",
    "      \"op\": 1704086820,\n",
    "      \"oa\": 1704094200,\n",
    "      \"fr\": [\n",
    "        {\n",
    "          \"n\": \"GENOVA P.PRINCIPE\",\n",
    "          \"ra\": \"N\",\n",
    "          \"rp\": \"2\",\n",
    "          \"oa\": 0,\n",
    "          \"op\": 1704086820\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"RONCO SCR.\",\n",
    "          \"ra\": \"0\",\n",
    "          \"rp\": \"2\",\n",
    "          \"oa\": 1704088200,\n",
    "          \"op\": 1704088260\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"ARQUATA SCRIVIA\",\n",
    "          \"ra\": \"1\",\n",
    "          \"rp\": \"4\",\n",
    "          \"oa\": 1704088740,\n",
    "          \"op\": 1704088800\n",
    "        },\n",
    "        {\n",
    "          \"n\": \"SERRAVALLE SCRIVIA\",\n",
    "          \"ra\": \"n.d.\",\n",
    "          \"rp\": \"1\",\n",
    "          \"oa\": 1704089160,\n",
    "          \"op\": 1704089220\n",
    "        },\n",
    "        ...\n",
    "      ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stops with 'n.d.' handled correctly. The final dataset contains 32549240 stops.\n"
     ]
    }
   ],
   "source": [
    "# Convert \"n.d.\" delays to NaN to handle them as missing values\n",
    "df_merged[\"stop_arrival_delay\"] = df_merged[\"stop_arrival_delay\"].replace(\"n.d.\", np.nan)\n",
    "df_merged[\"stop_departure_delay\"] = df_merged[\"stop_departure_delay\"].replace(\"n.d.\", np.nan)\n",
    "\n",
    "df_merged[\"stop_arrival_delay\"] = pd.to_numeric(df_merged[\"stop_arrival_delay\"], errors=\"coerce\")\n",
    "df_merged[\"stop_departure_delay\"] = pd.to_numeric(df_merged[\"stop_departure_delay\"], errors=\"coerce\")\n",
    "\n",
    "print(f\"Stops with 'n.d.' handled correctly. The final dataset contains {len(df_merged)} stops.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manage terminal station times**\n",
    "\n",
    "The destination stations do not have a departure time, and similarly, the departure stations do not have an arrival time.\n",
    "\n",
    "In the json files such times are denoted by '0'. \n",
    "\n",
    "To get around this problem, we can leave the missing values as NaT (Not a Time): In pandas dataframes, NaT is the standard for indicating a missing timestamp, just like NaN for numbers. Advanced machine learning models can handle NaT without problems, while an incorrect value such as “0” could compromise predictions.\n",
    "\n",
    "In addition, we add an is_terminal_stop column: This Boolean (True/False) column indicates whether the stop is the start or end station of the route. In this way, we can easily identify stops where arrival/departure values are missing legitimately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the boolean column for terminal stops\n",
    "df_merged[\"is_terminal_stop\"] = df_merged[\"stop_arrival_time\"].isna() | df_merged[\"stop_departure_time\"].isna()\n",
    "\n",
    "# Fill with NaT instead of 0\n",
    "df_merged[\"stop_arrival_time\"] = pd.to_datetime(df_merged[\"stop_arrival_time\"], errors=\"coerce\")\n",
    "df_merged[\"stop_departure_time\"] = pd.to_datetime(df_merged[\"stop_departure_time\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminal stops percentage: 17.05%\n"
     ]
    }
   ],
   "source": [
    "true_percentage = (df_merged[\"is_terminal_stop\"].sum() / len(df_merged)) * 100\n",
    "print(f\"Terminal stops percentage: {true_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Null values in the final dataset:\n",
      "                      Missing Values  Percentage\n",
      "stop_arrival_delay           7147420       21.96\n",
      "stop_departure_delay         3993550       12.27\n",
      "stop_arrival_time            2765755        8.50\n",
      "stop_departure_time          2783814        8.55\n"
     ]
    }
   ],
   "source": [
    "# Calculation and visualization of missing values\n",
    "missing_values = df_merged.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df_merged)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"Missing Values\": missing_values,\n",
    "    \"Percentage\": missing_percentage.round(2)\n",
    "})\n",
    "\n",
    "missing_summary = missing_summary[missing_summary[\"Missing Values\"] > 0]\n",
    "print(\"\\n Null values in the final dataset:\")\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of missing values in these two columns (8.5% + 8.55% = 17.05%) matches exactly with the percentage of `True` values in `is_terminal_stop`, confirming that our logic for flagging terminal stops is correct.  \n",
    "\n",
    "If the percentage of `True` in `is_terminal_stop` was higher or lower than the combined missing percentages in `stop_arrival_time` and `stop_departure_time`, it would indicate an inconsistency in the logic used to define terminal stops.  \n",
    "\n",
    "Since they match, we can be confident that `is_terminal_stop` is a **reliable feature** and accurately reflects whether a stop is terminal.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling delays at terminal stops**\n",
    "\n",
    "In the json files, `stop_arrival_delay` and `stop_departure_delay` times are denoted by 'N'. Infact, a train starts its journey from a departure station, meaning there is no previous stop to accumulate delay. A train ends its journey at the final station, meaning it does not have a next stop where departure delay would matter.\n",
    "\n",
    "Therefore, such null values are not true missing values, but expected structural absences. Filling them with 0 maintains logical consistency, prevents misinterpretation in downstream processing, and ensures clean data for analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.loc[df_merged[\"stop_arrival_time\"].isna(), \"stop_arrival_delay\"] = 0\n",
    "df_merged.loc[df_merged[\"stop_departure_time\"].isna(), \"stop_departure_delay\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valori nulli nel dataset finale:\n",
      "                      Missing Values  Percentage\n",
      "stop_arrival_delay           4383167       13.47\n",
      "stop_departure_delay         1212496        3.73\n",
      "stop_arrival_time            2765755        8.50\n",
      "stop_departure_time          2783814        8.55\n"
     ]
    }
   ],
   "source": [
    "# Calculation and visualization of missing values\n",
    "missing_values = df_merged.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df_merged)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"Missing Values\": missing_values,\n",
    "    \"Percentage\": missing_percentage.round(2)\n",
    "})\n",
    "\n",
    "missing_summary = missing_summary[missing_summary[\"Missing Values\"] > 0]\n",
    "print(\"\\n Valori nulli nel dataset finale:\")\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling Anomalous Delay Values in Train Data**  \n",
    "\n",
    "During data inspection, an issue was identified with the recorded arrival and departure delays for certain stops. As in the example, in the case of train 17633 at the Argenta station, the recorded arrival delay was an extremely large negative value, which is clearly incorrect.  \n",
    "\n",
    "A significantly negative delay is unrealistic. Such a massive negative value is likely due to a logging or data entry mistake. Infact, the timestamp for the arrival time (`oa = 100374615540`) is completely out of scale, suggesting that the data point is corrupted or misformatted.  \n",
    "Such anomalies could distort statistical analyses, predictions, and machine learning models if left unaddressed.  \n",
    "\n",
    "To ensure data reliability and prevent these errors from affecting further analysis, a data cleaning step was applied to remove rows with clearly anomalous delay values.  \n",
    "\n",
    "We defined reasonable thresholds for delays. Any records that exceeded these thresholds were automatically filtered out from the dataset.  \n",
    "\n",
    "<div style=\"max-height: 300px; overflow-y: auto; border: 1px solid #ccc; padding: 10px;\">\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"_id\": \"17633-1715787420-RkVSUkFSQQ==\",\n",
    "    \"n\": \"17633\",\n",
    "    \"p\": \"FERRARA\",\n",
    "    \"rp\": \"4\",\n",
    "    \"a\": \"RAVENNA\",\n",
    "    \"ra\": \"2\",\n",
    "    \"c\": \"REG\",\n",
    "    \"op\": 1715787420,\n",
    "    \"oa\": 1715791680,\n",
    "    \"fr\": [\n",
    "    {\n",
    "        \"n\": \"FERRARA\",\n",
    "        \"ra\": \"N\",\n",
    "        \"rp\": \"4\",\n",
    "        \"oa\": 0,\n",
    "        \"op\": 1715787420\n",
    "    },\n",
    "    {\n",
    "        \"n\": \"MONTESANTO\",\n",
    "        \"ra\": \"3\",\n",
    "        \"rp\": \"3\",\n",
    "        \"oa\": 1715788320,\n",
    "        \"op\": 1715788380\n",
    "    },\n",
    "    {\n",
    "        \"n\": \"PORTOMAGGIORE\",\n",
    "        \"ra\": \"2\",\n",
    "        \"rp\": \"3\",\n",
    "        \"oa\": 1715788740,\n",
    "        \"op\": 1715788860\n",
    "    },\n",
    "    {\n",
    "        \"n\": \"ARGENTA\",\n",
    "        \"ra\": \"-1644313770\",\n",
    "        \"rp\": \"1\",\n",
    "        \"oa\": 100374615540,\n",
    "        \"op\": 1715789400\n",
    "    },\n",
    "    ...\n",
    "    ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalous delays removed! The final dataset contains 32995541 stops.\n"
     ]
    }
   ],
   "source": [
    "# Define reasonable limits for delay in minutes\n",
    "MIN_DELAY = -10  # Maximum allowed early arrival\n",
    "MAX_DELAY = 300  # Maximum allowed delay\n",
    "\n",
    "df_merged = df_merged[\n",
    "    (df_merged[\"stop_arrival_delay\"].between(MIN_DELAY, MAX_DELAY, inclusive=\"both\")) &\n",
    "    (df_merged[\"stop_departure_delay\"].between(MIN_DELAY, MAX_DELAY, inclusive=\"both\"))\n",
    "]\n",
    "\n",
    "print(f\"Anomalous delays removed! The final dataset contains {len(df_stops)} stops.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows after cleaning\n",
    "final_rows_df = df_merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Null values in the final dataset:\n",
      "                     Missing Values  Percentage\n",
      "stop_arrival_time           2765720        9.86\n",
      "stop_departure_time         2774918        9.89\n"
     ]
    }
   ],
   "source": [
    "# Calculation and visualization of missing values\n",
    "missing_values = df_merged.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df_merged)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"Missing Values\": missing_values,\n",
    "    \"Percentage\": missing_percentage.round(2)\n",
    "})\n",
    "\n",
    "missing_summary = missing_summary[missing_summary[\"Missing Values\"] > 0]\n",
    "print(\"\\n Null values in the final dataset:\")\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data lost in the train dataset: 4935209 rows (14.96%)\n"
     ]
    }
   ],
   "source": [
    "loss_percentage_df = (1 - final_rows_df / initial_rows_df) * 100\n",
    "\n",
    "print(f\"Data lost in the train dataset: {initial_rows_df - final_rows_df} rows ({loss_percentage_df:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28064057, 17)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned datasets successfully saved in 'data/interim'\n"
     ]
    }
   ],
   "source": [
    "INTERIM_PATH = Path(\"data/interim\")\n",
    "INTERIM_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_merged.to_parquet(INTERIM_PATH / \"train_data_cleaned.parquet\", index=False)\n",
    "\n",
    "print(\"Cleaned datasets successfully saved in 'data/interim'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
