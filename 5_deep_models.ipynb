{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Models**\n",
    "\n",
    "**LSTM Model**  \n",
    "\n",
    "In this notebook, we test Long Short-Term Memory (LSTM) networks, a type of recurrent neural network (RNN) specifically designed to handle sequential data. LSTMs are well-suited for time-series problems as they can capture long-term dependencies and patterns in sequential data, overcoming the vanishing gradient problem that traditional RNNs face.  \n",
    "\n",
    "LSTMs achieve this by using a specialized memory cell structure with input, output, and forget gates, allowing the network to selectively retain and discard information over time. This makes them particularly effective for capturing trends, seasonality, and temporal relationships in our dataset. Given the sequential nature of our data, LSTMs provide a deep learning-based approach that complements our baseline XGBoost model, enabling us to explore potential improvements in predictive performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this LSTM (Long Short-Term Memory) implementation, several key techniques and \"tricks\" are used to improve model performance and learning:\n",
    "\n",
    "1. Sequence Creation Trick\n",
    "The `prepare_sequence_data()` function uses a sliding window approach to create sequences:\n",
    "- Transforms flat data into temporal sequences\n",
    "- Captures historical context by creating input sequences of fixed length\n",
    "- Allows the model to learn from previous time steps\n",
    "\n",
    "2. Time Series Cross-Validation Approach\n",
    "- Maintains chronological order during data splitting\n",
    "- Uses `shuffle=False` to preserve temporal dependencies\n",
    "- Ensures that training respects the time-based nature of the data\n",
    "\n",
    "3. LSTM Architecture Tricks\n",
    "- Multiple LSTM Layers (num_layers=2)\n",
    "  * Allows learning of more complex temporal representations\n",
    "  * Increases model capacity to capture intricate patterns\n",
    "\n",
    "- Dropout in LSTM\n",
    "  * Prevents overfitting\n",
    "  * Helps model generalize better by randomly dropping connections\n",
    "\n",
    "4. Hidden State Initialization\n",
    "```python\n",
    "h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "```\n",
    "- Explicitly initializes hidden and cell states\n",
    "- Ensures clean slate for each sequence processing\n",
    "- Moves initialization to the same device as input (GPU/CPU)\n",
    "\n",
    "5. Last Timestep Selection\n",
    "```python\n",
    "out = self.fc(out[:, -1, :])\n",
    "```\n",
    "- Uses only the last timestep for prediction\n",
    "- Captures the most recent temporal context\n",
    "- Allows final layer to make prediction based on entire sequence\n",
    "\n",
    "6. Adaptive Learning Techniques\n",
    "- Adam Optimizer\n",
    "  * Adaptive learning rates for each parameter\n",
    "  * Handles different scales of parameters effectively\n",
    "\n",
    "- Early stopping concept (implicitly through epoch-based training)\n",
    "  * Prevents overfitting by monitoring train/test losses\n",
    "\n",
    "7. Device Agnostic Training\n",
    "```python\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "```\n",
    "- Automatically uses GPU if available\n",
    "- Falls back to CPU seamlessly\n",
    "\n",
    "8. Loss and Metrics Tracking\n",
    "- Captures both training and validation losses\n",
    "- Enables detailed performance analysis\n",
    "- Helps diagnose potential overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_PATH = Path(\"data/processed\")\n",
    "MODELS_PATH = Path(\"models\")\n",
    "RESULTS_PATH = Path(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDelayLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.2):\n",
    "        super(TrainDelayLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence_data(df, target_col, sequence_length=5):\n",
    "    df = df.sort_values(by=['month', 'day_of_week', 'hour'])\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    sequences = np.array([X_scaled[i:i+sequence_length] for i in range(len(X_scaled) - sequence_length)])\n",
    "    targets = np.array(y.iloc[sequence_length:])\n",
    "    \n",
    "    return torch.FloatTensor(sequences), torch.FloatTensor(targets), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model(dataset_name, sequence_length=5):\n",
    "    df = pd.read_parquet(PROCESSED_PATH / f\"final_data{'_graph' if dataset_name == 'Graph' else ''}.parquet\")\n",
    "    X_seq, y_seq, scaler = prepare_sequence_data(df, 'stop_arrival_delay', sequence_length)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Training on {device}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    input_size = X_train.shape[2]\n",
    "    model = TrainDelayLSTM(input_size=input_size, hidden_size=64, num_layers=2, output_size=1).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    num_epochs = 50\n",
    "    train_losses, test_losses = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs.squeeze(), batch_y)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in test_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs.squeeze(), batch_y)\n",
    "                test_loss += loss.item()\n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(batch_y.numpy())\n",
    "    \n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "    r2 = r2_score(actuals, predictions)\n",
    "    \n",
    "    print(f\"{dataset_name} LSTM Results: MAE: {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), MODELS_PATH / f\"lstm_{dataset_name.lower()}.pth\")\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'Dataset': [dataset_name],\n",
    "        'MAE': [mae],\n",
    "        'RMSE': [rmse],\n",
    "        'R²': [r2]\n",
    "    })\n",
    "    results_df.to_csv(RESULTS_PATH / f\"lstm_results_{dataset_name.lower()}.csv\", index=False)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ningo\\AppData\\Local\\Temp\\ipykernel_30576\\3477508518.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 7.5206, Test Loss: 7.2234\n",
      "Epoch 11/50, Train Loss: 6.1366, Test Loss: 7.0710\n",
      "Epoch 21/50, Train Loss: 5.9853, Test Loss: 7.0898\n",
      "Epoch 31/50, Train Loss: 5.8029, Test Loss: 7.3709\n",
      "Epoch 41/50, Train Loss: 5.7511, Test Loss: 7.3962\n",
      "Base LSTM Results: MAE: 1.4044, RMSE: 2.7505, R²: 0.8841\n",
      "Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ningo\\AppData\\Local\\Temp\\ipykernel_30576\\3477508518.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 7.2703, Test Loss: 6.8586\n",
      "Epoch 11/50, Train Loss: 5.8482, Test Loss: 7.2969\n",
      "Epoch 21/50, Train Loss: 5.7264, Test Loss: 7.8746\n",
      "Epoch 31/50, Train Loss: 5.5576, Test Loss: 7.6156\n",
      "Epoch 41/50, Train Loss: 5.5001, Test Loss: 7.8699\n",
      "Graph LSTM Results: MAE: 1.3823, RMSE: 2.7842, R²: 0.8810\n"
     ]
    }
   ],
   "source": [
    "datasets = ['Base', 'Graph']\n",
    "\n",
    "for dataset in datasets:\n",
    "    train_lstm_model(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Results Analysis**\n",
    "\n",
    "The LSTM model was trained and evaluated on two datasets: one containing only the base features and another enriched with graph-based features. The results show that the model trained on the graph-enhanced dataset achieved a slightly lower Mean Absolute Error (MAE), indicating better performance in predicting small and frequent delays. Specifically, the MAE decreased from *1.4044* to *1.3823*.\n",
    "\n",
    "However, the Root Mean Squared Error (RMSE) increased slightly from *2.7505* to *2.7842*, and the R^2 score dropped from *0.8841* to *0.8810*. This suggests that while the graph features helped reduce average prediction errors, they may have introduced additional complexity or noise, leading to larger errors in some cases and slightly worse overall variance explained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Graph Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = \"other/train_network.graphml\"\n",
    "G = nx.read_graphml(graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_embeddings = pd.DataFrame(\n",
    "    [model.wv[key] for key in model.wv.key_to_index], \n",
    "    index=model.wv.key_to_index\n",
    ").reset_index().rename(columns={\"index\": \"station_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding salvati in other/station_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "embedding_path = \"other/station_embeddings.csv\"\n",
    "station_embeddings.to_csv(embedding_path, index=False)\n",
    "\n",
    "print(f\"Embedding salvati in {embedding_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Unire l'embedding al dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unire l'embedding del grafo al dataset e usarlo in un LSTM: ha senso?**\n",
    "**Dipende dallo scopo e da come intendi farlo.**\n",
    "Se vuoi unire l’embedding alle sequenze temporali e dare tutto in pasto a un LSTM, bisogna capire cosa rappresentano quegli embedding:\n",
    "\n",
    "L'embedding che hai calcolato rappresenta una **caratteristica stazionaria della rete** → Non cambia nel tempo.  \n",
    "In pratica, ogni stazione ha un vettore di embedding fisso che descrive la sua **posizione topologica** nella rete.\n",
    "\n",
    "Quando tu hai sequenze temporali tipo:\n",
    "```\n",
    "Giorno, Ora, Ritardo, ...\n",
    "```\n",
    "e gli aggiungi un embedding **fisso** come feature, stai dicendo al modello:\n",
    "> Oltre alle informazioni temporali, ti do anche informazioni strutturali sul nodo (stazione) coinvolto.\n",
    "\n",
    "**Quando questa scelta funziona bene**\n",
    "Se nei tuoi dati esiste una relazione **forte tra ritardi e posizione nella rete ferroviaria** (ad esempio: i ritardi si accumulano in stazioni centrali o di snodo), allora unire gli embedding ai dati temporali può aiutare.  \n",
    "L’LSTM potrà imparare che alcune stazioni tendono a causare ritardi cronici o sono colli di bottiglia.\n",
    "\n",
    "**Quando ha poco senso**\n",
    "Se il target che stai cercando di predire riguarda solo **ritardi a livello di singolo treno e dipende più da orari, condizioni e meno dalla topologia**, allora quell'embedding potrebbe non aggiungere molto e rischi di complicare inutilmente il modello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dal momento che ci serve la colonna stop_name per effettuare il merge con l'embedding, carichiamo il dataset non finale e ci lavoriamo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alleniamo la stessa LSTM di prima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrazione degli embedding strutturali nella rete LSTM\n",
    "Abbiamo esteso l’input dei nostri modelli sequenziali includendo embedding strutturali ottenuti tramite Node2Vec sul grafo ferroviario. Tali embedding rappresentano informazioni latenti sulla posizione topologica di ogni stazione nella rete.\n",
    "L’inclusione di queste informazioni consente alla rete LSTM di apprendere non solo le dinamiche temporali, ma anche le potenziali influenze strutturali legate alla posizione della stazione nella rete.\n",
    "Per evitare un aumento eccessivo della dimensionalità in input, è stato inoltre introdotto un livello di proiezione lineare che riduce la dimensionalità prima dell’input all’LSTM, migliorando l’efficienza computazionale e riducendo il rischio di overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_PATH = Path(\"data/processed\")\n",
    "OTHER_PATH = Path(\"other\")\n",
    "MODELS_PATH = Path(\"models\")\n",
    "RESULTS_PATH = Path(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(PROCESSED_PATH / \"train_data_fe.parquet\")\n",
    "embedding = pd.read_csv(OTHER_PATH / \"station_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(embedding, left_on=\"stop_name\", right_on=\"station_name\", how=\"left\")\n",
    "df.drop(columns=[\"station_name\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    \"scheduled_departure_time\", \n",
    "    \"scheduled_arrival_time\",\n",
    "    \"stop_departure_time\",\n",
    "    \"departure_station\", \"arrival_station\",\n",
    "    \"stop_name\"\n",
    "]\n",
    "df.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"train_avg_delay\"] = df.groupby(\"train_number\")[\"stop_arrival_delay\"].transform(\"mean\")\n",
    "df.drop(columns=[\"train_number\"], inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_cols = [col for col in df.columns if col.startswith('0') or col.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_full = PCA(n_components=64)\n",
    "pca_full.fit(df[embedding_cols])\n",
    "\n",
    "plt.plot(np.cumsum(pca_full.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "embedding_pca = pca.fit_transform(df[embedding_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cols = [f\"embed_pca_{i}\" for i in range(embedding_pca.shape[1])]\n",
    "df[pca_cols] = embedding_pca\n",
    "df.drop(columns=embedding_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA explained variance: 0.52\n"
     ]
    }
   ],
   "source": [
    "print(f\"PCA explained variance: {pca.explained_variance_ratio_.sum():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA sugli embedding del grafo**\n",
    "\n",
    "Per ridurre la dimensionalità degli embedding Node2Vec ottenuti dalla rete ferroviaria, abbiamo applicato la tecnica della Principal Component Analysis (PCA). L'obiettivo di questa riduzione è duplice: da un lato, eliminare ridondanze e rumore presenti nelle 64 dimensioni originarie; dall'altro, rendere il modello LSTM più efficiente in termini di tempo di training e inferenza, senza compromettere eccessivamente le informazioni rilevanti.\n",
    "\n",
    "Dopo aver applicato la PCA, abbiamo scelto di mantenere le prime 10 componenti principali, che spiegano complessivamente circa il 52% della varianza totale. Questo valore indica che oltre la metà dell'informazione contenuta negli embedding originali viene preservata nelle nuove feature. Sebbene non rappresenti la totalità della varianza, si tratta di un compromesso consapevole tra informazione e efficienza computazionale. Inoltre, abbiamo verificato che l’aggiunta di ulteriori componenti oltre le prime dieci avrebbe incrementato marginalmente la varianza spiegata, a fronte di un costo computazionale più elevato e un rischio maggiore di overfitting.\n",
    "\n",
    "Infine, la scelta di applicare la PCA è stata guidata anche dal contesto del problema: essendo gli embedding Node2Vec basati sulla struttura topologica del grafo, parte dell’informazione geometrica e relazionale è ridondante rispetto alle feature già presenti nel dataset, rendendo la compressione tramite PCA una soluzione efficace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDelayLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.2):\n",
    "        super(TrainDelayLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence_data(df, target_col, sequence_length=5):\n",
    "    df = df.sort_values(by=['month', 'day_of_week', 'hour'])\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    sequences = np.array([X_scaled[i:i+sequence_length] for i in range(len(X_scaled) - sequence_length)])\n",
    "    targets = np.array(y.iloc[sequence_length:])\n",
    "    return torch.FloatTensor(sequences), torch.FloatTensor(targets), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_embedding(sequence_length=5):\n",
    "    X_seq, y_seq, scaler = prepare_sequence_data(df, 'stop_arrival_delay', sequence_length)\n",
    "    split_idx = int(len(X_seq) * 0.8)\n",
    "    X_train, X_test = X_seq[:split_idx], X_seq[split_idx:]\n",
    "    y_train, y_test = y_seq[:split_idx], y_seq[split_idx:]\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Training on {device}\")\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    input_size = X_train.shape[2]\n",
    "    model = TrainDelayLSTM(input_size=input_size, hidden_size=64, num_layers=2, output_size=1).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    scaler_amp = GradScaler()\n",
    "\n",
    "    num_epochs = 50\n",
    "    train_losses, test_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs.squeeze(), batch_y)\n",
    "            scaler_amp.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler_amp.step(optimizer)\n",
    "            scaler_amp.update()\n",
    "            train_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in test_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs.squeeze(), batch_y)\n",
    "                test_loss += loss.item()\n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}')\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(batch_y.numpy())\n",
    "\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "    r2 = r2_score(actuals, predictions)\n",
    "\n",
    "    print(f\"\\nLSTM + Graph Embedding Results: MAE: {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), MODELS_PATH / \"lstm_graph_embedding.pth\")\n",
    "    pd.DataFrame({\n",
    "        'MAE': [mae],\n",
    "        'RMSE': [rmse],\n",
    "        'R²': [r2]\n",
    "    }).to_csv(RESULTS_PATH / \"lstm_results_graph_embedding.csv\", index=False)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Epoch 1/50, Train Loss: 7.0670, Test Loss: 6.6708\n",
      "Epoch 11/50, Train Loss: 5.8065, Test Loss: 7.0272\n",
      "Epoch 21/50, Train Loss: 5.6950, Test Loss: 6.8323\n",
      "Epoch 31/50, Train Loss: 5.5213, Test Loss: 6.8007\n",
      "Epoch 41/50, Train Loss: 5.4656, Test Loss: 6.9126\n",
      "\n",
      "LSTM + Graph Embedding Results: MAE: 1.3548, RMSE: 2.6320, R²: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainDelayLSTM(\n",
       "  (lstm): LSTM(28, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lstm_embedding(sequence_length=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
